{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D Sphere Bayesian Optimisation Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **Bayesian Optimisation on a 4D sphere** ($S^3$) using geometric kernels. The 3-sphere is embedded in $\\mathbb{R}^4$ and triangulated using Delaunay triangulation.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Point Cloud & Triangulation**: 100 points sampled uniformly on $S^3$, then Delaunay triangulated\n",
    "2. **Mesh Laplacian**: Custom eigendecomposition of the mesh Laplacian (cotangent formula)\n",
    "3. **Geometric Kernel**: Matérn kernel adapted for manifold geometry using the Karhunen-Loève expansion\n",
    "4. **Bayesian Optimisation**: Discrete BO on mesh vertices using Expected Improvement acquisition\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. Package installation and imports\n",
    "2. Mesh and kernel setup (loading pre-computed eigendecomposition)\n",
    "3. Objective function definition\n",
    "4. Bayesian Optimisation loop\n",
    "5. Visualisation of BO progress\n",
    "6. Kernel geometry-awareness demonstration\n",
    "7. Convergence analysis\n",
    "\n",
    "**Note**: Since the 4D sphere cannot be directly visualised, we project to 3D using the first three coordinates. This is for intuition only - the kernel operates in the full 4D space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Package Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pymanopt matplotlib ipympl kaleido plotly scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import norm\n",
    "from pathlib import Path\n",
    "\n",
    "# Geometric kernels\n",
    "import geometric_kernels\n",
    "from geometric_kernels.spaces import Mesh\n",
    "from geometric_kernels.kernels import MaternKarhunenLoeveKernel\n",
    "from geometric_kernels.spaces.eigenfunctions import EigenfunctionsFromEigenvectors\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configure plotly for GitHub Codespaces (use 'notebook' renderer for inline display)\n",
    "# Use 'notebook' for Jupyter environments like Codespaces, 'browser' for local\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Mesh and Kernel Setup\n",
    "\n",
    "We load the pre-computed 4D sphere mesh and its Laplacian eigendecomposition. The eigenvalues and eigenvectors were computed using the n-dimensional cotangent formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "MeshFolder_dir = Path.cwd()\n",
    "print(\"Working directory:\", MeshFolder_dir)\n",
    "\n",
    "# Load the mesh (OBJ file for geometric_kernels compatibility)\n",
    "Filename = \"Delaunay 100point sphere.obj\"\n",
    "MESH = Mesh.load_mesh(str(MeshFolder_dir / Filename))\n",
    "print(f\"Mesh loaded with {MESH.num_vertices} vertices\")\n",
    "\n",
    "# Load pre-computed eigendecomposition\n",
    "eigenvals = np.load(MeshFolder_dir / \"4D_eigenvals.npy\").reshape(-1, 1)\n",
    "eigenvectors = np.load(MeshFolder_dir / \"4D_eigenvecs.npy\")  # Shape: (N, N) where N = num_vertices\n",
    "\n",
    "# Load the original 4D points (for coordinate-based objective functions)\n",
    "points_4D = np.load(MeshFolder_dir / \"Delaunay_4D_points.npy\")  # Shape: (N, 4)\n",
    "\n",
    "print(f\"Eigenvalues shape: {eigenvals.shape}\")\n",
    "print(f\"Eigenvectors shape: {eigenvectors.shape}\")\n",
    "print(f\"4D points shape: {points_4D.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the domain (vertex indices)\n",
    "num_verts = MESH.num_vertices\n",
    "whole_domain = np.atleast_2d(np.arange(1, num_verts + 1)).T\n",
    "\n",
    "# Create eigenfunctions from pre-computed eigenvectors\n",
    "eigenfunctions = EigenfunctionsFromEigenvectors(eigenvectors=eigenvectors)\n",
    "\n",
    "# Create the Matérn kernel with Karhunen-Loève expansion\n",
    "# dimension=4 since we're on a 3-sphere (embedded in R^4)\n",
    "kernel = MaternKarhunenLoeveKernel(\n",
    "    space=MESH,\n",
    "    eigenfunctions=eigenfunctions,\n",
    "    eigenvalues_laplacian=eigenvals,\n",
    "    num_levels=eigenvectors.shape[0],\n",
    "    dimension=4,  # 4D embedding dimension\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Kernel hyperparameters\n",
    "LENGTH_SCALE = 0.3  # Controls correlation decay with geodesic distance\n",
    "NU = 0.4  # Smoothness parameter\n",
    "\n",
    "# Initialize kernel parameters\n",
    "params = kernel.init_params()\n",
    "params[\"lengthscale\"] = np.array([LENGTH_SCALE])\n",
    "params[\"nu\"] = np.array([NU])\n",
    "\n",
    "print(f\"Kernel configured with lengthscale={LENGTH_SCALE}, nu={NU}\")\n",
    "print(f\"Domain size: {num_verts} vertices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Objective Function\n",
    "\n",
    "We define a simple objective function based on the first 4D coordinate. This gives us a function with a clear minimum on the sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x):\n",
    "    \"\"\"\n",
    "    Objective function: returns the first coordinate of the 4D point.\n",
    "    \n",
    "    Args:\n",
    "        x: Node index (1-indexed) or array of indices\n",
    "    \n",
    "    Returns:\n",
    "        The first coordinate value(s)\n",
    "    \"\"\"\n",
    "    if isinstance(x, np.ndarray):\n",
    "        idx = np.int64(x.flatten()) - 1  # Convert to 0-indexed\n",
    "        return points_4D[idx, 0].flatten()[0] if len(idx) == 1 else points_4D[idx, 0]\n",
    "    else:\n",
    "        return points_4D[x - 1, 0]\n",
    "\n",
    "# Vectorised version for batch evaluation\n",
    "objective_vectorized = np.vectorize(objective_function)\n",
    "\n",
    "# Compute objective values for all vertices\n",
    "objective_vals = objective_vectorized(np.arange(1, num_verts + 1))\n",
    "\n",
    "print(f\"Objective value range: [{objective_vals.min():.4f}, {objective_vals.max():.4f}]\")\n",
    "print(f\"True minimum value: {objective_vals.min():.4f} at index {np.argmin(objective_vals) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Bayesian Optimisation Functions\n",
    "\n",
    "We implement the Expected Improvement acquisition function and the main BO loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration-exploitation trade-off: higher xi encourages more exploration\n",
    "XI_DEFAULT = 0.9\n",
    "\n",
    "def expected_improvement(mu, sigma, f_best, xi=XI_DEFAULT):\n",
    "    \"\"\"\n",
    "    Calculate Expected Improvement (EI) acquisition function.\n",
    "    \n",
    "    Args:\n",
    "        mu: Posterior mean vector\n",
    "        sigma: Posterior standard deviation vector\n",
    "        f_best: Best observed function value (we minimise)\n",
    "        xi: Exploration-exploitation trade-off parameter (default: 0.9 for exploration)\n",
    "    \n",
    "    Returns:\n",
    "        EI values for each point\n",
    "    \"\"\"\n",
    "    mu = mu.reshape(-1, 1)\n",
    "    sigma = sigma.reshape(-1, 1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Z = (f_best - mu - xi) / sigma\n",
    "        ei = (f_best - mu - xi) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei = np.where(sigma > 1e-10, ei, 0.0)\n",
    "    \n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BO_loop(num_iterations, x_obs=None, objective_func=None):\n",
    "    \"\"\"\n",
    "    Run Bayesian Optimisation loop.\n",
    "    \n",
    "    Args:\n",
    "        num_iterations: Number of BO iterations\n",
    "        x_obs: Initial observed points (1-indexed vertex indices)\n",
    "        objective_func: Objective function to optimise\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (posterior_mean, posterior_var, EI, observed_X, observed_Y)\n",
    "    \"\"\"\n",
    "    if objective_func is None:\n",
    "        objective_func = objective_function\n",
    "    if x_obs is None:\n",
    "        x_obs = np.array([[np.random.randint(1, num_verts + 1)]])\n",
    "    \n",
    "    # Evaluate objective at initial points\n",
    "    y_observed = np.atleast_2d(\n",
    "        np.apply_along_axis(objective_func, 1, x_obs)\n",
    "    ).reshape(-1, 1)\n",
    "    \n",
    "    # Prior covariance matrix\n",
    "    K_XX_prior = kernel.K(params, whole_domain - 1, whole_domain - 1)\n",
    "    mu_prior_vector = np.zeros((num_verts, 1))\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # GP posterior computation\n",
    "        m_vector = mu_prior_vector[x_obs.flatten() - 1]\n",
    "        K_xX = kernel.K(params, x_obs - 1, whole_domain - 1)\n",
    "        K_xx = kernel.K(params, x_obs - 1, x_obs - 1)\n",
    "        K_Xx = K_xX.T\n",
    "        \n",
    "        # Add regularisation for numerical stability (jitter term)\n",
    "        # 1e-6 is a standard choice to prevent singular matrices while preserving accuracy\n",
    "        JITTER = 1e-6\n",
    "        K_xx_stable = K_xx + np.eye(K_xx.shape[0]) * JITTER\n",
    "        C_inv = np.linalg.pinv(K_xx_stable)\n",
    "        \n",
    "        # Posterior mean and variance\n",
    "        mew_vec = mu_prior_vector + K_Xx @ C_inv @ (y_observed - m_vector)\n",
    "        Current_K_matrix = K_XX_prior - K_Xx @ C_inv @ K_xX\n",
    "        Sigma_vec = np.diag(Current_K_matrix).copy().reshape(-1, 1)\n",
    "        Sigma_vec[Sigma_vec < 0] = 0  # Ensure non-negative variance\n",
    "        \n",
    "        # Compute acquisition function\n",
    "        EI_vec = expected_improvement(mew_vec, np.sqrt(Sigma_vec), np.min(y_observed))\n",
    "        \n",
    "        # Select next point (greedy)\n",
    "        next_point = np.argmax(EI_vec) + 1\n",
    "        next_point = np.atleast_2d(next_point)\n",
    "        \n",
    "        # Evaluate and update\n",
    "        y_next = np.atleast_2d(objective_func(next_point))\n",
    "        x_obs = np.vstack((x_obs, next_point))\n",
    "        y_observed = np.vstack((y_observed, y_next))\n",
    "    \n",
    "    return mew_vec, Sigma_vec, EI_vec, x_obs, y_observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Run Bayesian Optimisation\n",
    "\n",
    "We run BO with different iteration counts to observe how the posterior evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Random initial point\n",
    "initial_point = np.array([[np.random.randint(1, num_verts + 1)]])\n",
    "print(f\"Initial point: vertex {initial_point[0,0]}\")\n",
    "print(f\"Initial objective value: {objective_vals[initial_point[0,0]-1]:.4f}\")\n",
    "\n",
    "# Run BO with different iteration counts\n",
    "mu_1, sigma_1, ei_1, X_1, Y_1 = BO_loop(1, x_obs=initial_point.copy())\n",
    "mu_2, sigma_2, ei_2, X_2, Y_2 = BO_loop(5, x_obs=initial_point.copy())\n",
    "mu_3, sigma_3, ei_3, X_3, Y_3 = BO_loop(10, x_obs=initial_point.copy())\n",
    "\n",
    "print(\"\\n--- Results Summary ---\")\n",
    "print(f\"After 1 iteration:  Best observed = {Y_1.min():.4f}\")\n",
    "print(f\"After 5 iterations: Best observed = {Y_2.min():.4f}\")\n",
    "print(f\"After 10 iterations: Best observed = {Y_3.min():.4f}\")\n",
    "print(f\"\\nTrue minimum: {objective_vals.min():.4f} at vertex {np.argmin(objective_vals) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Visualisation Helper Functions\n",
    "\n",
    "Since we're visualising a 4D sphere, we project to 3D using the first three coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_figure(fig):\n",
    "    \"\"\"Apply clean styling to a plotly figure.\"\"\"\n",
    "    fig.update_layout(scene_aspectmode=\"cube\")\n",
    "    fig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "    fig.update_layout(margin=dict(l=0, r=0, t=40, b=0))\n",
    "    fig.update_layout(plot_bgcolor=\"rgba(0,0,0,0)\", paper_bgcolor=\"rgba(0,0,0,0)\")\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(showbackground=False, showticklabels=False, visible=False),\n",
    "            yaxis=dict(showbackground=False, showticklabels=False, visible=False),\n",
    "            zaxis=dict(showbackground=False, showticklabels=False, visible=False),\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def create_mesh_trace(values, name, colorscale='Viridis', showscale=True):\n",
    "    \"\"\"\n",
    "    Create a 3D scatter trace for mesh vertices colored by values.\n",
    "    Projects 4D points to 3D using first three coordinates.\n",
    "    \"\"\"\n",
    "    values_flat = values.ravel()\n",
    "    \n",
    "    # Use first 3 coordinates for 3D projection\n",
    "    trace = go.Scatter3d(\n",
    "        x=points_4D[:, 0],\n",
    "        y=points_4D[:, 1],\n",
    "        z=points_4D[:, 2],\n",
    "        mode='markers',\n",
    "        name=name,\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=values_flat,\n",
    "            colorscale=colorscale,\n",
    "            showscale=showscale,\n",
    "            colorbar=dict(title=name, x=0.9) if showscale else None\n",
    "        ),\n",
    "        customdata=np.column_stack([values_flat, np.arange(1, num_verts + 1), points_4D[:, 3]]),\n",
    "        hovertemplate=(\n",
    "            f\"{name}: %{{customdata[0]:.4f}}<br>\" +\n",
    "            \"Vertex: %{customdata[1]}<br>\" +\n",
    "            \"4th coord: %{customdata[2]:.4f}<br>\" +\n",
    "            \"<extra></extra>\"\n",
    "        )\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def create_points_trace(X_indices, name, color):\n",
    "    \"\"\"Create a scatter trace for observed points.\"\"\"\n",
    "    coords = points_4D[X_indices.flatten() - 1]\n",
    "    trace = go.Scatter3d(\n",
    "        x=coords[:, 0],\n",
    "        y=coords[:, 1],\n",
    "        z=coords[:, 2],\n",
    "        mode='markers',\n",
    "        name=name,\n",
    "        marker=dict(size=10, color=color, symbol='diamond')\n",
    "    )\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Visualise BO Progress\n",
    "\n",
    "Compare the posterior mean at different iteration counts with the true objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure comparing posteriors\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for different iterations\n",
    "fig.add_trace(create_mesh_trace(mu_1, 'Posterior (1 iter)', 'Blues', showscale=False))\n",
    "fig.add_trace(create_mesh_trace(mu_2, 'Posterior (5 iter)', 'Greens', showscale=False))\n",
    "fig.add_trace(create_mesh_trace(mu_3, 'Posterior (10 iter)', 'Oranges', showscale=False))\n",
    "fig.add_trace(create_mesh_trace(objective_vals, 'True Objective', 'hot', showscale=True))\n",
    "\n",
    "# Add observed points\n",
    "fig.add_trace(create_points_trace(X_2, 'Sampled (5 iter)', 'cyan'))\n",
    "fig.add_trace(create_points_trace(X_3, 'Sampled (10 iter)', 'purple'))\n",
    "\n",
    "# Style and show\n",
    "fig = update_figure(fig)\n",
    "fig.update_layout(\n",
    "    title='Bayesian Optimisation on 4D Sphere (projected to 3D)',\n",
    "    legend=dict(x=0.02, y=0.98)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of sampled values\n",
    "print(\"\\n--- Sampled Values (sorted, ascending) ---\")\n",
    "print(f\"After 5 iterations: {sorted(Y_2.flatten())}\")\n",
    "print(f\"After 10 iterations: {sorted(Y_3.flatten())}\")\n",
    "print(f\"\\nTrue best value: {objective_vals.min():.4f}\")\n",
    "print(f\"Initial point value: {objective_vals[initial_point[0,0]-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Kernel Geometry-Awareness Demonstration\n",
    "\n",
    "Visualise how the kernel spreads covariance from a single source point across the mesh. Points with high kernel values are more correlated with the source point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kernel_influence(source_point):\n",
    "    \"\"\"\n",
    "    Visualise kernel influence from a single source point.\n",
    "    \n",
    "    Args:\n",
    "        source_point: 0-indexed source vertex\n",
    "    \n",
    "    Returns:\n",
    "        Plotly figure\n",
    "    \"\"\"\n",
    "    source_idx = np.atleast_2d([source_point])\n",
    "    all_points = np.atleast_2d(np.arange(num_verts)).T\n",
    "    \n",
    "    # Compute kernel values from source to all points\n",
    "    K_influence = kernel.K(params, source_idx, all_points).flatten()\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add influence trace\n",
    "    fig.add_trace(create_mesh_trace(K_influence, 'Kernel Value', 'Viridis', showscale=True))\n",
    "    \n",
    "    # Mark source point\n",
    "    source_coord = points_4D[source_point]\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[source_coord[0]], \n",
    "        y=[source_coord[1]], \n",
    "        z=[source_coord[2]],\n",
    "        mode='markers',\n",
    "        marker=dict(size=15, color='red', symbol='diamond'),\n",
    "        name='Source Point'\n",
    "    ))\n",
    "    \n",
    "    fig = update_figure(fig)\n",
    "    fig.update_layout(title=f\"Kernel Influence from Vertex {source_point + 1}\")\n",
    "    \n",
    "    return fig, K_influence\n",
    "\n",
    "# Visualise kernel influence from a specific point\n",
    "source_vertex = 3  # 0-indexed\n",
    "influence_fig, kernel_values = visualize_kernel_influence(source_vertex)\n",
    "influence_fig.show()\n",
    "\n",
    "print(f\"\\nKernel influence statistics:\")\n",
    "print(f\"  Min: {kernel_values.min():.4f}\")\n",
    "print(f\"  Max: {kernel_values.max():.4f} (at source)\")\n",
    "print(f\"  Mean: {kernel_values.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. BO Convergence Analysis\n",
    "\n",
    "Plot how the best observed value improves over iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run longer BO experiment for convergence analysis\n",
    "np.random.seed(123)\n",
    "n_iterations = 20\n",
    "initial_point_conv = np.array([[np.random.randint(1, num_verts + 1)]])\n",
    "\n",
    "# Collect convergence data\n",
    "best_values = []\n",
    "x_obs_conv = initial_point_conv.copy()\n",
    "y_obs_conv = np.atleast_2d(objective_function(x_obs_conv)).reshape(-1, 1)\n",
    "best_values.append(y_obs_conv.min())\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    mu_temp, sigma_temp, ei_temp, x_obs_conv, y_obs_conv = BO_loop(\n",
    "        1, x_obs=x_obs_conv, objective_func=objective_function\n",
    "    )\n",
    "    best_values.append(y_obs_conv.min())\n",
    "\n",
    "# Plot convergence\n",
    "fig_conv, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(range(len(best_values)), best_values, 'b-o', linewidth=2, markersize=8, label='Best Observed')\n",
    "ax.axhline(y=objective_vals.min(), color='r', linestyle='--', linewidth=2, label=f'True Minimum ({objective_vals.min():.4f})')\n",
    "ax.set_xlabel('Iteration', fontsize=12)\n",
    "ax.set_ylabel('Best Objective Value', fontsize=12)\n",
    "ax.set_title('BO Convergence on 4D Sphere', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bo_convergence_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nConvergence Summary:\")\n",
    "print(f\"  Initial value: {best_values[0]:.4f}\")\n",
    "print(f\"  Final value:   {best_values[-1]:.4f}\")\n",
    "print(f\"  True minimum:  {objective_vals.min():.4f}\")\n",
    "print(f\"  Gap to optimal: {best_values[-1] - objective_vals.min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Additional Analysis: Kernel vs Geodesic Distance\n",
    "\n",
    "Examine the relationship between kernel values and approximate geodesic distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise kernel matrix\n",
    "K_full = kernel.K(params, whole_domain - 1, whole_domain - 1)\n",
    "\n",
    "# Compute Euclidean distances (approximation of geodesic on sphere)\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "euclidean_dists = squareform(pdist(points_4D, 'euclidean'))\n",
    "\n",
    "# For a sphere, geodesic distance ≈ arcsin(chord_distance/2) * 2 * radius\n",
    "# For unit sphere: geodesic ≈ 2 * arcsin(euclidean/2)\n",
    "geodesic_approx = 2 * np.arcsin(np.clip(euclidean_dists / 2, 0, 1))\n",
    "\n",
    "# Scatter plot: kernel value vs geodesic distance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Extract upper triangle (excluding diagonal)\n",
    "upper_idx = np.triu_indices(num_verts, k=1)\n",
    "geodesic_flat = geodesic_approx[upper_idx]\n",
    "kernel_flat = K_full[upper_idx]\n",
    "\n",
    "ax.scatter(geodesic_flat, kernel_flat, s=3, alpha=0.5, c='blue')\n",
    "ax.set_xlabel('Approximate Geodesic Distance', fontsize=12)\n",
    "ax.set_ylabel('Kernel Value', fontsize=12)\n",
    "ax.set_title('Kernel Decay with Geodesic Distance on 4D Sphere', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe kernel respects geodesic geometry:\")\n",
    "print(\"- High kernel values for nearby points (small geodesic distance)\")\n",
    "print(\"- Low kernel values for distant points (large geodesic distance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This demo showed:\n",
    "\n",
    "1. **Custom Eigendecomposition**: Loading pre-computed mesh Laplacian eigenvectors/eigenvalues for a 4D sphere\n",
    "2. **Geometric Kernel**: Using `MaternKarhunenLoeveKernel` with dimension=4 to properly scale the kernel\n",
    "3. **Bayesian Optimisation**: Discrete BO on mesh vertices using Expected Improvement\n",
    "4. **Visualisation**: 3D projection of the 4D sphere for intuition\n",
    "5. **Geometry-Awareness**: The kernel correctly captures geodesic relationships on the sphere\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- The kernel exploits the manifold structure to spread information based on geodesic distance\n",
    "- BO converges to near-optimal solutions within a few iterations\n",
    "- The 3D projection is for visualisation only; the kernel operates in the full 4D space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
